{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45d99c30",
   "metadata": {},
   "source": [
    "# START HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44e83f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jetson/yolov3\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jetson/yolov3\n",
    "\n",
    "import cv2\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import json\n",
    "import os.path as osp\n",
    "import pickle\n",
    "\n",
    "import base64\n",
    "import io\n",
    "\n",
    "from models import *  # set ONNX_EXPORT in models.py\n",
    "from utils.datasets import *\n",
    "from utils.utils import *\n",
    "\n",
    "def img_arr_to_b64(img_arr):\n",
    "    \"\"\"taken from https://raw.githubusercontent.com/wkentaro/labelme/master/labelme/utils/image.py\"\"\"\n",
    "    img_pil = PIL.Image.fromarray(img_arr)\n",
    "    f = io.BytesIO()\n",
    "    img_pil.save(f, format=\"PNG\")\n",
    "    img_bin = f.getvalue()\n",
    "    if hasattr(base64, \"encodebytes\"):\n",
    "        img_b64 = base64.encodebytes(img_bin)\n",
    "    else:\n",
    "        img_b64 = base64.encodestring(img_bin)\n",
    "    return img_b64\n",
    "\n",
    "def dets_to_shapes(dets):\n",
    "    dets = dets.split('\\n')[:-1]\n",
    "    shapes = []\n",
    "    for det in dets:\n",
    "        det = det.split()\n",
    "        l, t, r, b, score = det[:5]\n",
    "        l = float(l)\n",
    "        t = float(t)\n",
    "        r = float(r)\n",
    "        b = float(b)\n",
    "#        l = int(l)\n",
    "#        t = int(t)\n",
    "#        r = int(r)\n",
    "#        b = int(b)\n",
    "        \n",
    "        score = float(score)\n",
    "        label = ' '.join(det[5:])\n",
    "        \n",
    "        shape = dict(label = label,\n",
    "                     line_color = 'null',\n",
    "                     fill_color = 'null',\n",
    "                     points = [[l, t], [r,b]],\n",
    "                     shape_type = 'rectangle'\n",
    "                     )\n",
    "        shapes.append(shape)\n",
    "        \n",
    "    stat = {}\n",
    "    for shape in shapes:\n",
    "        key = shape['label']\n",
    "        if key in stat.keys():\n",
    "            stat[key] += 1\n",
    "        else:\n",
    "            stat[key] = 1\n",
    "#    print(stat)\n",
    "    return shapes        \n",
    "    \n",
    "def yolo_to_labelme(dets, img):\n",
    "    res_json = {}\n",
    "    res_json['version'] = '4.5.6'\n",
    "    res_json['flags'] = {}\n",
    "    res_json['imagePath'] = ''\n",
    "    res_json['imageHeight'] = img.shape[0]\n",
    "    res_json['imageWidth'] = img.shape[1]\n",
    "    res_json['imageData'] = img_arr_to_b64(img).decode('utf-8')\n",
    "    res_json['shapes'] = dets_to_shapes(dets)  \n",
    "    return res_json\n",
    "\n",
    "\n",
    "class LoadWebcam:  # for inference\n",
    "    def __init__(self, pipe=0, img_size=608, crop=True):\n",
    "        self.img_size = img_size\n",
    "\n",
    "        if pipe == '0':\n",
    "            pipe = 0  # local camera\n",
    "        # pipe = 'rtsp://192.168.1.102/1'  # IP camera\n",
    "        # pipe = 'rtsp://username:password@192.168.1.64/1'  # IP camera with login\n",
    "        # pipe = 'rtsp://170.93.143.139/rtplive/470011e600ef003a004ee33696235daa'  # IP traffic camera\n",
    "        # pipe = 'http://wmccpinetop.axiscam.net/mjpg/video.mjpg'  # IP golf camera\n",
    "\n",
    "        # https://answers.opencv.org/question/215996/changing-gstreamer-pipeline-to-opencv-in-pythonsolved/\n",
    "        # pipe = '\"rtspsrc location=\"rtsp://username:password@192.168.1.64/1\" latency=10 ! appsink'  # GStreamer\n",
    "\n",
    "        # https://answers.opencv.org/question/200787/video-acceleration-gstremer-pipeline-in-videocapture/\n",
    "        # https://stackoverflow.com/questions/54095699/install-gstreamer-support-for-opencv-python-package  # install help\n",
    "        # pipe = \"rtspsrc location=rtsp://root:root@192.168.0.91:554/axis-media/media.amp?videocodec=h264&resolution=3840x2160 protocols=GST_RTSP_LOWER_TRANS_TCP ! rtph264depay ! queue ! vaapih264dec ! videoconvert ! appsink\"  # GStreamer\n",
    "        \n",
    "        self.pipe = pipe\n",
    "        self.open_cam()\n",
    "        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 3)  # set buffer size\n",
    "        self.crop = crop\n",
    "    \n",
    "    def open_cam(self):\n",
    "        self.cap = cv2.VideoCapture(self.pipe)  # video capture object\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.count = -1\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        self.count += 1\n",
    "        if cv2.waitKey(1) == ord('q'):  # q to quit\n",
    "            self.cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            raise StopIteration\n",
    "\n",
    "        # Read frame\n",
    "        if self.pipe == 0:  # local camera\n",
    "            ret_val, img0 = self.cap.read()\n",
    "#            img0 = cv2.flip(img0, 1)  # flip left-right\n",
    "        else:  # IP camera\n",
    "            n = 0\n",
    "            while True:\n",
    "                n += 1\n",
    "                self.cap.grab()\n",
    "                if n % 30 == 0:  # skip frames\n",
    "                    ret_val, img0 = self.cap.retrieve()\n",
    "                    if ret_val:\n",
    "                        break\n",
    "\n",
    "        # Print\n",
    "        assert ret_val, 'Camera Error %s' % self.pipe\n",
    "\n",
    "        if self.crop:\n",
    "            # take quadratic crop from the center of the image\n",
    "            img_h, img_w = img0.shape[:2]\n",
    "            \n",
    "            # prevent crop from being out of frame\n",
    "            self.img_size = min(img_h, img_w, self.img_size)\n",
    "            \n",
    "            l, t = int((img_w - self.img_size)/2), int((img_h - self.img_size)/2)\n",
    "            r, b = l + self.img_size, t + self.img_size\n",
    "            img = img0[t:b, l:r, :].copy()\n",
    "        else:\n",
    "            # Padded resize\n",
    "            img = letterbox(img0, new_shape=self.img_size)[0]\n",
    "\n",
    "        # Convert\n",
    "        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
    "        img = np.ascontiguousarray(img)\n",
    "\n",
    "        return img, img0\n",
    "\n",
    "    def __len__(self):\n",
    "        return 0\n",
    "    \n",
    "\n",
    "class CamInfer():\n",
    "    def __init__(self, \n",
    "                 imgsz=608, \n",
    "                 source='0', \n",
    "                 out='output', \n",
    "                 cfg='cfg/yolov3.cfg', \n",
    "                 weights='yolov3.pt', \n",
    "                 names='data/coco.names'):\n",
    "        self.imgsz = imgsz\n",
    "        self.out = out\n",
    "        self.weights = weights\n",
    "        self.cfg = cfg \n",
    "            \n",
    "        # Initialize\n",
    "        self.device = torch_utils.select_device(device=\"0\")\n",
    "\n",
    "        # Initialize model\n",
    "        self.model = Darknet(cfg, self.imgsz)\n",
    "\n",
    "        # Load weights\n",
    "        if self.weights.endswith('.pt'):  # pytorch format\n",
    "            self.model.load_state_dict(torch.load(self.weights, map_location=self.device)['model'])\n",
    "        else:  # darknet format\n",
    "            load_darknet_weights(self.model, self.weights)\n",
    "\n",
    "        # Eval mode\n",
    "        self.model.to(self.device).eval()\n",
    "        \n",
    "        # Init dataloader\n",
    "        self.dataset = LoadWebcam(source, img_size=imgsz)\n",
    "        \n",
    "        torch.backends.cudnn.benchmark = True  # set True to speed up constant image size inference\n",
    "\n",
    "        # Get names and colors\n",
    "        self.names = load_classes(names)\n",
    "        self.colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(self.names))]\n",
    "\n",
    "        # Run inference\n",
    "        img = torch.zeros((1, 3, self.imgsz, self.imgsz), device=self.device)  # init img\n",
    "        _ = self.model(img.float())  # run once\n",
    "        \n",
    "\n",
    "    def detect(self, spam, stop_event):\n",
    "        if not self.dataset.cap.isOpened():\n",
    "            self.dataset.open_cam()\n",
    "\n",
    "        self.pred = ''\n",
    "        \n",
    "        while not stop_event.is_set():\n",
    "            img, im0s = next(iter(self.dataset))\n",
    "            self.img = img.copy()\n",
    "            \n",
    "            img = torch.from_numpy(self.img).to(self.device)\n",
    "            img = img.float()  # uint8 to fp16/32\n",
    "            img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "            if img.ndimension() == 3:\n",
    "                img = img.unsqueeze(0)\n",
    "\n",
    "            # Inference\n",
    "            t1 = torch_utils.time_synchronized()\n",
    "            pred = self.model(img, augment=False)[0]\n",
    "            t2 = torch_utils.time_synchronized()\n",
    "        \n",
    "            # Apply NMS\n",
    "            pred = non_max_suppression(pred)\n",
    "            \n",
    "            # render pred\n",
    "            self.pred = ''\n",
    "            img_pred = cam.img.transpose(1,2,0).copy()\n",
    "            for i, det in enumerate(pred):  # detections for image i\n",
    "                s = ''\n",
    "                img_h, img_w = img_pred.shape[:2]\n",
    "                s += f'{img_h}x{img_w}. '  # print image_size to string\n",
    "                if det is not None and len(det):\n",
    "                    # Print results\n",
    "                    for c in det[:, -1].unique():\n",
    "                        n = (det[:, -1] == c).sum()  # detections per class\n",
    "                        s += f'{n} {self.names[int(c)]}s, '  # detections add to string\n",
    "\n",
    "                    # Write results\n",
    "                    for *xyxy, conf, cls in reversed(det):\n",
    "                        label = f'{conf:.2f} {self.names[int(cls)]}'\n",
    "                        plot_one_box(xyxy, img_pred, label=label, color=self.colors[int(cls)])\n",
    "                        \n",
    "                        self.pred += f'{xyxy[0]:.2f} {xyxy[1]:.2f} {xyxy[2]:.2f} {xyxy[3]:.2f} {label}\\n'\n",
    "                        \n",
    "            self.img_pred = img_pred\n",
    "            self.s = s\n",
    "#            print(f'\\r{self.s}. ({1/(t2 - t1):.3f} fps)', end='')\n",
    "            \n",
    "        self.dataset.cap.release()\n",
    "        assert not self.dataset.cap.isOpened(), print('camera release error')\n",
    "        \n",
    "            \n",
    "    def stop(self):\n",
    "        self.run = False\n",
    "        \n",
    "\n",
    "# stock weights\n",
    "#cam = CamInfer(imgsz=480, cfg='cfg/yolov3.cfg', weights='yolov3.weights', names='data/coco.names')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4cfc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ret, frame = cam.dataset.cap.read()\n",
    "#ret, frame.shape, cam.img.shape, cam.img_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2a7f1d",
   "metadata": {},
   "source": [
    "# STREAMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ef6e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import struct\n",
    "from time import time\n",
    "import socket                   # Import socket module\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "class VideoStream():\n",
    "    def __init__(self, cam, host='172.25.207.82', port=6001):\n",
    "        self.cam = cam\n",
    "        self.port = port                     # Reserve a port for your service.\n",
    "        self.s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)             # Create a socket object\n",
    "        self.s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "        self.host = host\n",
    "        self.s.bind((host, port))            # Bind to the port\n",
    "        self.s.listen(5)                     # Now wait for client connection.\n",
    "        print('Streaming server listening....')\n",
    "        self.pause_stream = False\n",
    "        \n",
    "    def start(self):\n",
    "        self.conn, self.addr = self.s.accept()  # Establish connection with client.\n",
    "        print('Got connection from', self.addr)\n",
    "\n",
    "        \n",
    "    def reset(self):\n",
    "        self.conn.close()\n",
    "        print('Server listening....')\n",
    "        \n",
    "        self.start()\n",
    "        \n",
    "    def stop(self):\n",
    "        self.conn.close()\n",
    "        self.s.close()\n",
    "        \n",
    "        \n",
    "    def transmit(self, cam, stop_event):\n",
    "        \"\"\"\n",
    "        infinite loop for labelme jsons streaming\n",
    "        :args:\n",
    "            :cam: instance of CamInfer class\n",
    "            :stop_event: instance of threading.Event() class\n",
    "        \"\"\"\n",
    "        self.start()\n",
    "        img_size = self.cam.img.transpose((1,2,0)).shape\n",
    "        still_img = np.zeros(img_size).astype(np.uint8)\n",
    "        cv2.putText(still_img, 'stream on pause', (20, 40), 1, 2, (255,255,255), 2)\n",
    "        \n",
    "        counter = 1\n",
    "        start = time()\n",
    "        while not stop_event.is_set():\n",
    "            tic = time()\n",
    "            if self.pause_stream:\n",
    "                labelme_json = yolo_to_labelme('', still_img)\n",
    "            else:\n",
    "                img = self.cam.img.transpose((1,2,0)).copy()\n",
    "                labelme_json = yolo_to_labelme(self.cam.pred, img)\n",
    "        \n",
    "            serialized_data = pickle.dumps(labelme_json)\n",
    "            message = struct.pack(\"Q\", len(serialized_data)) + serialized_data\n",
    "            try:\n",
    "                self.conn.sendall(message)\n",
    "                # print(f'\\r{counter/(time()-start):.2f} fps', end='')\n",
    "                print(f'\\r{1/(time()-tic):.2f} fps', end='')\n",
    "                counter += 1\n",
    "            except:\n",
    "                print()\n",
    "                self.reset()\n",
    "                \n",
    "        self.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf958743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vs_stop_event.set()\n",
    "#stop_event.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec7fc7d",
   "metadata": {},
   "source": [
    "# WEIGHTS SOCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed0fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning server listening....\n",
      "Using CUDA device0 _CudaDeviceProperties(name='Xavier', total_memory=7773MB)\n",
      "\n",
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "Model Summary: 222 layers, 6.15237e+07 parameters, 6.15237e+07 gradients, 116.3 GFLOPS\n",
      "connected to the camera True\n",
      "Streaming server listening....\n",
      "Got connection from ('172.25.27.193', 62798)\n",
      "0.67 fps\n",
      "Server listening....\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import cv2\n",
    "from time import sleep\n",
    "import threading\n",
    "import pickle\n",
    "import struct\n",
    "import socket                   # Import socket module\n",
    "\n",
    "\n",
    "host = '172.25.207.82'  # Standard loopback interface address (localhost)\n",
    "port = 6000        # Port to listen on (non-privileged ports are > 1023)\n",
    "\n",
    "s = socket.socket()             # Create a socket object\n",
    "s.bind((host, port))            # Bind to the port\n",
    "s.listen()                     # Now wait for client connection.\n",
    "print('Learning server listening....')\n",
    "\n",
    "S_PORT = 6001\n",
    "while True:\n",
    "    # stock COCO model\n",
    "#    cam = CamInfer(imgsz=480, cfg='cfg/yolov3.cfg', weights='yolov3.weights', names='data/coco.names')\n",
    "    # custom 1 class trained model\n",
    "    cam = CamInfer(imgsz=480, cfg='cfg/yolov3-1cls_my.cfg', weights='best.weights', names='data/obj.names')\n",
    "    stop_event= threading.Event()\n",
    "    t = threading.Thread(target=cam.detect, args=(0, stop_event), daemon=True)\n",
    "    t.start()\n",
    "\n",
    "    sleep(5)\n",
    "    ret, frame = cam.dataset.cap.read()\n",
    "    print(f'connected to the camera {ret}')\n",
    "\n",
    "\n",
    "    # connect stream to camera \n",
    "    try:\n",
    "        vs = VideoStream(cam)\n",
    "        \n",
    "        vs_stop_event= threading.Event()\n",
    "        vs_t = threading.Thread(target=vs.transmit, args=(cam, vs_stop_event), daemon=True)\n",
    "        vs_t.start()\n",
    "        vs.pause_stream = False\n",
    "\n",
    "    except:\n",
    "        vs.cam = cam\n",
    "        vs.pause_stream = False\n",
    "    \n",
    "    # trying to get new weights from trainer\n",
    "    conn, addr = s.accept()  # Establish connection with client.\n",
    "    print()\n",
    "    print('Got connection from', addr)\n",
    "    \n",
    "    # receive and save new weights\n",
    "    data = b\"\"\n",
    "    payload_size = struct.calcsize(\"Q\")\n",
    "\n",
    "    # recieving data size\n",
    "    while len(data) < payload_size:\n",
    "        packet = conn.recv(4 * 1024)  # 4K\n",
    "        if not packet:\n",
    "            break\n",
    "        data += packet\n",
    "    packed_msg_size = data[:payload_size]\n",
    "    msg_size = struct.unpack(\"Q\", packed_msg_size)[0]\n",
    "    print(msg_size)\n",
    "\n",
    "\n",
    "    # recieving data\n",
    "    data = data[payload_size:]\n",
    "    while len(data)<msg_size:\n",
    "        data += conn.recv(2**18)\n",
    "        print(f'\\r{len(data)}', end='')\n",
    "        if not data:\n",
    "            break\n",
    "\n",
    "    conn.close()\n",
    "    \n",
    "    with open('/home/jetson/yolov3/best.weights', 'wb') as f:\n",
    "        f.write(data)\n",
    "    \n",
    "    # release camera to load new weights for inference \n",
    "    stop_event.set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90481b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd6c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ~/.local/share/Trash/*\n",
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b8dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vs.pause_stream = True\n",
    "vs_stop_event.set()\n",
    "stop_event.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b72666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('rtsp://ubuntu:ubuntu@192.168.0.102:8554/stream1')\n",
    "\n",
    "ret, frame = cap.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ffd1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da64e8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
